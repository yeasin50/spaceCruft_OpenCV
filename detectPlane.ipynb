{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames= []\n",
    "classFilePath = 'data/coco.names'\n",
    "with open(classFilePath,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 000001CF1E90EF10>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configPath = 'data/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'data/frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectColor =(244,5,20)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "fontSize = 1\n",
    "fontColor = (255, 0, 255)\n",
    "\n",
    "thres = 0.5 # Threshold to detect object\n",
    "nms_thres = .5 # 0-1 higer value means lower suppress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize a bit \n",
    "imgHeight, imgWidth, _ = img.shape\n",
    "scale= 60\n",
    "imgH = int (imgHeight *scale /100)\n",
    "imgW = int (imgWidth * scale /100)\n",
    "img = cv2.resize(img, (imgW, imgH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'testImages/tb2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, tuple)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "type(confs),type(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formating data\n",
    "bbox = list(bbox)\n",
    "confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "confs = list(map(float,confs ))\n",
    "\n",
    "indics = cv2.dnn.NMSBoxes(bbox, confs, thres, nms_thres) # remove overlaps\n",
    "\n",
    "for ind in indics:\n",
    "    i = ind[0] # ind returns list we need index only\n",
    "    box = bbox[i]\n",
    "\n",
    "    if classNames[classIds[i][0]-1] == \"cell phone\":\n",
    "        cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "        \n",
    "        rectBox = box\n",
    "        print(box)\n",
    "#         print()\n",
    "        #show accuracy level\n",
    "        cv2.putText(img, str(round(confs[i]*100, 1)), (box[0]+10, box[1]+10), \n",
    "                   font, fontSize, fontColor, 1)\n",
    "        #putting name of object \n",
    "        cv2.putText(img, classNames[classIds[i][0]-1], (box[0]+70, box[1]+30), \n",
    "                   font, fontSize, fontColor,1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Object detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59 207 106 158]\n",
      "59 207 106 158\n"
     ]
    }
   ],
   "source": [
    "print(rectBox)\n",
    "(x, y) = (rectBox[0], rectBox[1])\n",
    "(w, h) = (rectBox[2], rectBox[3])\n",
    "print(x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "# need make it flexiable \n",
    "detectW =  30\n",
    "startX= x+(w//2) # center X\n",
    "print(startX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img, (startX- detectW, y),(startX +detectW, y+50), (220,1,0),2 )\n",
    "# cv2.imwrite(\"LabRatimage.jpg\", img)\n",
    "cv2.circle(img, (startX, y), 13, (0,0,222))\n",
    "cv2.imshow(\"Object detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Cam version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, img = cam.read()\n",
    "    if success:\n",
    "        classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "        \n",
    "        #Formating data\n",
    "        bbox = list(bbox)\n",
    "        confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "        confs = list(map(float,confs ))\n",
    "\n",
    "        indics = cv2.dnn.NMSBoxes(bbox, confs, .1, nms_thres) # remove overlaps\n",
    "        \n",
    "        for ind in indics:\n",
    "            i = ind[0] # ind returns list we need index only\n",
    "            box = bbox[i]\n",
    "            \n",
    "            if classNames[classIds[i][0]-1] == \"cell phone\":\n",
    "                cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "\n",
    "                #show accuracy level\n",
    "                cv2.putText(img, str(round(confs[i]*100, 1)), (box[0]+10, box[1]+10), \n",
    "                           font, fontSize, fontColor, 1)\n",
    "                #putting name of object \n",
    "                cv2.putText(img, classNames[classIds[i][0]-1], (box[0]+70, box[1]+30), \n",
    "                           font, fontSize, fontColor,1)\n",
    "\n",
    "    \n",
    "        cv2.imshow(\"Object detection\", img)\n",
    "        if cv2.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
